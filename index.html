<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Zhang, Shuning (张书宁)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=BMKN-NwAAAAJ" class="menu-item">Google Scholar</a></div>
<div class="menu-item"><a href="https://github.com/zhangsn-19">GitHub</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Zhang, Shuning (张书宁) </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://zhangsn-19.github.io/"><img src="avatar.jpg" alt="Shuning Zhang" width="150px" height="210px" /></a>&nbsp;</td>
<td align="left"><p><b>Ph.D., </b> <br />
Institute for Network Sciences and Cyberspace, Tsinghua University <br />
Beijing, China <br /> 
<b>Bachelor, </b> <br />
Computer Science and Technology, Tsinghua University <br />
Beijing, China<br />
E-mail: <a href="mailto:Zhang.sn314@gmail.com">Zhang.sn314@gmail.com</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I received the B.S. degree from Tsinghua University major in Computer Science and Technology, in 2023. My research interest lies in Human-Computer Interaction (HCI), especially interaction techniques and Human-AI collaboration.<br />
I am currently a Ph.D. student in Usable Privacy Lab (UP Lab), advised by <b>Prof. Xin Yi</b>, Tsinghua Univesity, Beijing, China. I focus on <strong>privacy and security problems</strong> in various interaction devices and interfaces. 

During my studies, I gained valuable research experience through internships at several institutions: the University of California, Los Angeles (UCLA) with Prof. Nanyun Peng, Stanford University with Prof. James Landay, and the University of Washington (UW) with Prof. Anind K. Dey.

Specifically, my research interest focused on usable privacy and security issues during human-AI interaction, including investigating mitigation strategies of errors during human-AI collaboration (e.g., mistrust caused by hallucination of LLMs) and privacy issues when adopting AI system (e.g., smarthome personal assistant). </p>

<h3>First or Co-first Author Publications</h3>
<ol class="publication-list">
  
    <!-- 第一作者示例 -->
    <li class="first-author">
      <div class="teaser">
        <img src="opg.png" alt="opg Paper Teaser" width="210">
      </div>
      <div class="pub-info">
        <span class="author-highlight">Shuning Zhang</span>, et al. 
        <span class="paper-title">Actual Achieved Gain and Optimal Perceived Gain: Modeling Human Take-over Decisions Towards Automated Vehicles' Suggestions</span> 
        <span class="venue">(CHI'25)</span>
      </div>
    </li>
  
    <!-- 共同一作示例 -->
    <li class="first-author">
      <div class="teaser">
        <img src="privcap.png" alt="privcap Paper Teaser" width="210">
      </div>
      <div class="pub-info">
        <span class="author-highlight">Shuning Zhang</span>, et al. 
        <span class="paper-title">PrivCAP: An Interactive CAPTCHA-like Technique to Facilitate Effective Comprehension of Mobile Privacy Policy</span> 
        <span class="venue">(CHI'25)</span>
      </div>
    </li>

    <li class="other-author">
        <div class="teaser">
          <img src="privacy.png" alt="privacy valuation Paper Teaser" width="210">
        </div>
        <div class="pub-info">
          Lihua Fan, <span class="author-highlight">Shuning Zhang</span>, et al. 
          <span class="paper-title">Evaluating the Privacy Valuation of Personal Data on Smartphones</span> 
          <span class="venue">(IMWUT'24)</span>
          <a href="https://dl.acm.org/doi/pdf/10.1145/3678509" class="doi-link">Paper</a>
        </div>
      </li>
  
    <!-- 其他作者示例 -->
    <li class="other-author">
      <div class="teaser">
        <img src="squeezin.jpg" alt="SqueeezIn Paper Teaser" width="210">
      </div>
      <div class="pub-info">
        Xin Yi, <span class="author-highlight">Shuning Zhang</span>, et al. 
        <span class="paper-title">Squeez'In: Private Authentication on Smartphones based on Squeezing Gestures</span> 
        <span class="venue">(CHI'23)</span>
        <a href="https://dl.acm.org/doi/pdf/10.1145/3544548.3581419" class="doi-link">Paper</a>
      </div>
    </li>
    <!-- 其他条目按相同结构添加 -->
</ol>

<h3>Other Publications</h3>


<ol>
<li><p>Yongquan Hu, Jingyu Tang, Xinya Gong, Zhongyi Zhou, <b>Shuning Zhang</b>, et al. Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design. (CHI'25)</p>
</li>
<li><p>Sheng Zhao, Junrui Zhu, <b>Shuning Zhang</b>, et al. CoordAuth: Hands-Free Two-Factor Authentication in Virtual Reality Leveraging Head-Eye Coordination. (IEEE VR'25)</p>
</li>
<li><p>Xueyang Wang, Runyan Tian, Qiuyi Zeng, Chenye Tu, <b>Shuning Zhang</b>, et al. The Synergy of Dialogue and Art: Exploring the Potential of Multimodal AI Chatbots in Emotional Support. (CSCW'24 poster)</p>
</li>
<li><p>Yongquan Hu, <b>Shuning Zhang</b>, et al. Exploring Large-Scale Language Models to Evaluate EEG-Based Multimodal Data for Mental Health. (Ubicomp'24 Companion)</p>
</li>
</li>
<li><p>Jackie Yang, Karina Li, Daniel Wan Rosli, <b>Zhang S</b>, et al. ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '24)</p>
</li>
<li><p>Xin Yi, Yan Kong, Xueze Kang, <b>Zhang S</b>, et al. Exploring Interactive Gestures with Voice Assistant on HMDs in Social Situations. In 2024 IEEE virtual reality (VR) </p>
</li>
<li><p>Hsu I H, Huang K H, <b>Zhang S</b>, et al. TAGPRIME: A unified framework for relational structure extraction[C]//Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023: 12917-12932.</p>
</li>
<li><p>Li S, <b>Zhang S</b>, Chen G, et al. Towards Benchmarking and Assessing Visual Naturalness of Physical World Adversarial Attacks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 12324-12333.</p>
</li> 
</ol>

<p><a href="https://scholar.google.com/citations?hl=zh-CN&user=BMKN-NwAAAAJ">Full list of publications in Google Scholar</a>.</p>
<h3>Academic service</h3>
<p><b>Reviewer</b></p>
<ul> 
<li><p>ACL 2022</p>
</li>
<li><p>CHI 2024 case studies</p>
</li>
<li><p>CSCW 2024 posters</p>
</li>
<li><p>Ubicomp/ISWC 2024 Workshop</p>
</li>
<li><p>ISS 2024</p>
</li>
<li><p>ICMI 2024 poster</p>
</li>
<li><p>CHI 2025 Case Studies</p>
</li>
<li><p>Chinese CHI 2025</p>
</li>
<li><p>IMWUT 2025</p>
</li>
<li><p>CSCW 2025</p>
</li>
</ul>
<p><b>Program Chair</b></p>
<ul> 
<li><p>Chinese CHI 2025</p>
</li>

</td>
</tr>
</table>
</body>
</html>
