<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Zhang, Shuning (张书宁)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://github.com/zhangsn-19">GitHub</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Zhang, Shuning (张书宁) </h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://zhangsn-19.github.io/"><img src="bio.jpg" alt="alt text" width="150px" height="210px" /></a>&nbsp;</td>
<td align="left"><p><b>Ph.D., </b> <br />
Institute for Network Sciences and Cyberspace, Tsinghua University <br />
Beijing, China <br /> 
<b>Bachelor, </b> <br />
Computer Science and Technology, Tsinghua University <br />
Beijing, China<br />
E-mail: <a href="mailto:Zhang.sn314@gmail.com">Zhang.sn314@gmail.com</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I received the B.S. degree from Tsinghua University major in Computer Science and Technology, in 2023. My research interest lies in Human-Computer Interaction (HCI), especially interaction techniques and Human-AI collaboration.<br />
I am currently a Ph.D. student in Usable Privacy Lab (UP Lab), advised by <b>Prof. Xin Yi</b>, Tsinghua Univesity, Beijing, China. I focus on <strong>privacy and security problems</strong> in various interaction devices and interfaces. Specifically, my research area included investigating mitigation strategies of errors during human-AI collaboration (e.g., mistrust caused by hallucination of LLMs) and privacy issues when adopting AI system (e.g., smarthome personal assistant). </p>
<h2>Research</h2>
<h3>Research interests</h3>
<ul>
<li><p>Security and Privacy Problems of Human-AI Collaboration (especially LLMs) </p>
</li>
<li><p>Privacy Perception of End Users</p>
</li>
<li><p>Misinformation Understanding and Governance</p>
</li>
<li><p>Authentication</p>
</li>
</ul>
<h3>Current work</h3>
<h4>Privacy in Human-AI Interaction</h4>
<ul>
<li><p>Exploring and Resolving Private Memory Concerns of Human-LLM Interaction
</p>
</li>
<li><p>Adanonymizer: Privacy-Utility Adapative Anonymization System of Generative AI
</p>
</li>
<li><p>Exploring and Resolving Multi-modal Privacy Issues in Human-LLM Interaction
</p>
</li>
</ul>
<h4>Privacy Perception and Mitigation</h4>
<ul>
<li>
<p>Exploring Effectiveness of Privacy Protection Mechanism of IoT Devices (completed)
</p>
</li>
<li><p>PrivCAPTCHA: Facilitating Users' Privacy Awareness through Embedding Privacy Policy into CAPTCHA
</p>
</li>
<li><p>Exploring Cognition of Privacy Threats with different Transmission and Sharing Range of Smarthome Personal Assistant (completed)
</p>
</li>
</ul>
<h4>Misinformation Governance</h4>
<ul>
<li>
<p>Designing Annotation Chain-based Decentralized Methods to Improve Misinformation Governance
</p>
</li>
<li>
<p>Human-in-the-loop Misinformation Governance Leveraging Reinforcement Learning
</p>
</li>
</ul>
<h4>Authentication</h4>
<ul>
<li><p>rPPG Pairing (completed) <i>(Collaborator)</i>
</p>
</li>
<li><p>Head-eye Collaborative Authentication in Head-mounted Display (HMD) (completed) <i>(Advisor)</i>
</p>
</li>
<li><p>How to Quantify the Longitudinal Stability of Behavioural Biometric Authentication: A Survey
</p>
</li>
<li><p>Subtle Facial Expression based Authentication
</p>
</li>
</ul>
<h4>Trust</h4>
<ul>
<li><p>Exploring Effect of Expression Style on Human's Trust Towards LLM's Misinformation and Hallucination</p>
</li>
<li><p>Exploring the Dark Patterns of Conversational AI through Voice Manipulation</p>
</li>
</ul>
<h4>Misc</h4>
<ul>
<li><p>
    EEG guided Mental Healing System (completed) <i>(Collaborator)</i>
</p></li>  
<li><p>
    Exploring the Effect of a Emphathic Mediator on Interaction between Humans <i>(Collaborator)</i>
</p></li>   
<li><p>
    Full-body Motion Classification Using Waist-sEMG for Mixed Reality Scenarios
</p></li>
<li><p>
    Prochatter: Resolving Ambiguity in Searching during the Collaboration between Human and Conversational AI driven by LLMs (CA-LLMs) (completed)
</p></li>  
</ul>
<h3>Publications </h3>
<ol>
<li><p><b>Shuning Zhang</b>, et al. Actual Achieved Gain and Optimal Perceived Gain: Modeling Human Take-over Decisions Towards Automated Vehicles' Suggestions (CHI'25)</p>
</li>
<li><p><b>Shuning Zhang</b>, et al. PrivCAP: An Interactive CAPTCHA-like Technique to Facilitate Effective Comprehension of Mobile Privacy Policy (CHI'25)</p>
</li>
<li><p>Yongquan Hu, Jingyu Tang, Xinya Gong, Zhongyi Zhou, <b>Shuning Zhang</b>, et al. Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design. (CHI'25)</p>
</li>
<li><p>Sheng Zhao, Junrui Zhu, <b>Shuning Zhang</b>, et al. CoordAuth: Hands-Free Two-Factor Authentication in Virtual Reality Leveraging Head-Eye Coordination. (IEEE VR'25)</p>
</li>
<li><p>Xueyang Wang, Runyan Tian, Qiuyi Zeng, Chenye Tu, <b>Shuning Zhang</b>, et al. The Synergy of Dialogue and Art: Exploring the Potential of Multimodal AI Chatbots in Emotional Support. (CSCW'24 poster)</p>
</li>
<li><p>Yongquan Hu, <b>Shuning Zhang</b>, et al. Exploring Large-Scale Language Models to Evaluate EEG-Based Multimodal Data for Mental Health. (Ubicomp'24 Companion)</p>
</li>
<li><p>Lihua Fan*, <b>Shuning Zhang*</b>, et al. Evaluating the Privacy Valuation of Personal Data on Smartphones. (Ubicomp'24)</p>
</li>
<li><p>Jackie Yang, Karina Li, Daniel Wan Rosli, <b>Zhang S</b>, et al. ReactGenie: A Development Framework for Complex Multimodal Interactions Using Large Language Models. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '24)</p>
</li>
<li><p>Xin Yi, Yan Kong, Xueze Kang, <b>Zhang S</b>, et al. Exploring Interactive Gestures with Voice Assistant on HMDs in Social Situations. In 2024 IEEE virtual reality (VR) </p>
</li>
<li><p>Hsu I H, Huang K H, <b>Zhang S</b>, et al. TAGPRIME: A unified framework for relational structure extraction[C]//Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023: 12917-12932.</p>
</li>
<li><p>Li S, <b>Zhang S</b>, Chen G, et al. Towards Benchmarking and Assessing Visual Naturalness of Physical World Adversarial Attacks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 12324-12333.</p>
</li> 
<li><p>Xin Yi, <b>Shuning Zhang</b>, Ziqi Pan, Louisa Shi, Fengyan Han, Yan Kong, Hewu Li, and Yuanchun Shi. 2023. Squeez’In: Private Authentication on Smartphones based on Squeezing Gestures. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23). Association for Computing Machinery, New York, NY, USA, Article 532, 1–15. https://doi.org/10.1145/3544548.3581419</p>
</li> 
</ol>
<p><a href="https://scholar.google.com/citations?hl=zh-CN&user=BMKN-NwAAAAJ">Full list of publications in Google Scholar</a>.</p>
<h3>Academic service</h3>
<p><b>Reviewer</b></p>
<ul> 
<li><p>ACL 2022</p>
</li>
<li><p>CHI 2024 case studies</p>
</li>
<li><p>CSCW 2024 posters</p>
</li>
<li><p>Ubicomp/ISWC 2024 Workshop</p>
</li>
<li><p>ISS 2024</p>
</li>
<li><p>ICMI 2024 poster</p>
</li>
<li><p>CHI 2025 Case Studies</p>
</li>
<li><p>Chinese CHI 2025</p>
</li>
<li><p>IMWUT 2025</p>
</li>
<li><p>CSCW 2025</p>
</li>
</ul>
<p><b>Program Chair</b></p>
<ul> 
<li><p>Chinese CHI 2025</p>
</li>

</td>
</tr>
</table>
</body>
</html>
